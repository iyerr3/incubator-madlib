"""
@file correlation.py_in

@brief Cross-correlation function for multiple columns of a relation

@namespace correlation
"""
import plpy
from time import time
from utilities.utilities import unique_string, add_postfix
from utilities.utilities import py_list_to_sql_string

def correlation(schema_madlib, source_table, output_table,
                target_cols, verbose, **kwargs):
    """
    Populates an output table with the coefficients of correlation between
    the columns in a source table
    Args:
        @param schema_madlib  MADlib schema namespace
        @param source_table   Name of input table
        @param output_table   Name of output table
        @param target_cols    Name of specific columns targetted for correlation
        @param verbose        Flag to determine whether to output debug info

    Returns:
        Tuple (output table name, number of columns, time for computation)
    """
    _validate_corr_arg(source_table, output_table)
    _numeric_column_names, _nonnumeric_column_names = _get_numeric_columns(source_table)
    _target_cols = _analyze_target_cols(target_cols)
    _nonexisting_target_cols = None
    if _target_cols:
        # prune all non-numeric column types from target columns
        # ensure all column names are unique since we'll use them as output
        # column names
        _existing_target_cols = list(set(column for column in _target_cols
                                         if column in _numeric_column_names))
        _nonexisting_target_cols = list(set(_target_cols)
                                        - set(_existing_target_cols)
                                        - set(_nonnumeric_column_names))
        _nonnumeric_target_cols = list(set(_target_cols)
                                       & set(_nonnumeric_column_names))
    else:
        # if target_cols not provided then all numeric columns are to be targeted
        _existing_target_cols = _numeric_column_names[:]
        _nonnumeric_target_cols = _nonnumeric_column_names[:]

    if len(_existing_target_cols) == 0:
        plpy.error("Correlation error: No numeric column found in the target list.")
    if len(_existing_target_cols) == 1:
        plpy.error("Correlation error: Only one numeric column found in the target list.")

    # ---- Output message ----
    output_text_mesasge = "Summary for 'correlation' function"
    if _nonnumeric_target_cols:
        output_text_mesasge += ("\n Non-numeric columns ignored: {0}".
                                format(str(_nonnumeric_target_cols)))
    if _nonexisting_target_cols:
        output_text_mesasge += ("\n Columns that don't exist in '{0}' ignored: {1}".
                                format(source_table, str(_nonexisting_target_cols)))

    output_text_mesasge += ("\n Producing correlation for columns: {0}".
                            format(str(_existing_target_cols)))
    plpy.info(output_text_mesasge)
    # ---- Output message ----

    return _populate_output_table(schema_madlib, source_table, output_table,
                                  _existing_target_cols, verbose)


# -----------------------------------------------------------------------
# Argument validation function
# -----------------------------------------------------------------------
def _validate_corr_arg(source_table, output_table):
    """
    Validates all arguments and raises an error if there is an invalid argument

    Args:
        @param source_table         Name of input table (string)
        @param output_table         Name of output table (string)
        @param target_cols          Comma separated list of output columns (string)

    Returns:
        True if all arguments are valid
    """
    if not source_table or source_table.strip() == '':
        plpy.error("""
            Correlation error: Invalid source table name""")
    try:
        plpy.execute("SELECT '{0}'::regclass::oid\
                                    ".format(source_table))[0]['oid']
    except:
        plpy.error("Correlation error:  Relation '{0}' does not exist\
                        ".format(source_table))
    rowcount = plpy.execute("""
        SELECT count(*) FROM {0}""".format(source_table))[0]['count']
    if rowcount == 0:
        plpy.error("Relation '{0}' is empty".format(source_table))

    if not output_table or output_table.strip() == '':
        plpy.error("Correlation error: Invalid output table name")
    return True


# -----------------------------------------------------------------------
# Get all column names in source table
# -----------------------------------------------------------------------
def _get_numeric_columns(source_table):
    """
    Returns all column names for numeric type columns in a relation

    Args:
        @param source_table

    Returns:
        List of column names in table
    """
    # determine the exact table_schema and table_name
    # in case that source_table only contains table_name
    row = plpy.execute("""
                        SELECT
                            quote_ident(nspname) AS table_schema,
                            quote_ident(relname) AS table_name
                        FROM
                            pg_class AS c,
                            pg_namespace AS nsp
                        WHERE
                            c.oid = '{source_table}'::regclass::oid AND
                            c.relnamespace = nsp.oid
                        """.format(source_table=source_table))
    table_schema = row[0]['table_schema']
    table_name = row[0]['table_name']

    # retrieve the numeric columns
    numeric_types = ('smallint', 'integer', 'bigint',
                     'real', 'numeric', 'double precision')
    all_columns = plpy.execute("""
                                SELECT quote_ident(column_name) as column_name,
                                       data_type
                                FROM
                                    information_schema.columns
                                WHERE
                                    quote_ident(table_schema) = '{table_schema}' AND
                                    quote_ident(table_name) = '{table_name}'
                                ORDER BY ordinal_position
                                """.format(table_schema=table_schema,
                                           table_name=table_name))
    all_col_names = set(column['column_name'] for column in all_columns)
    num_col_names = [column['column_name'] for column in all_columns
                     if column['data_type'] in numeric_types]
    nonnum_col_names = list(all_col_names - set(num_col_names))

    return (num_col_names, nonnum_col_names)


# -----------------------------------------------------------------------
# Input parameter checks and edits
# -----------------------------------------------------------------------
def _analyze_target_cols(target_cols):
    """
    Analyzes target_cols string input and converts it to a list
    """
    if not target_cols or target_cols.strip() in ('', '*'):
        target_cols = None
    else:
        target_cols = target_cols.replace(' ', '').split(',')
    return target_cols


# -----------------------------------------------------------------------
# Create and populate output table
# -----------------------------------------------------------------------
def _populate_output_table(schema_madlib, source_table, output_table,
                           col_names, verbose):
    """
    Creates a relation with the appropriate number of columns given a list of
    column names and populates with the correlation coefficients. If the table
    already exists, then it is dropped before creating.

    Args:
        @param schema_madlib  Schema of MADlib
        @param source_table   Name of source table
        @param output_table   Name of output table
        @param _target_cols   Name of all columns to place in output table

    Returns:
        Tuple (output table name, number of columns, time for computation)
    """
    old_msg_level = plpy.execute("""
        SELECT setting FROM pg_settings
        WHERE name='client_min_messages'
        """)[0]['setting']
    if verbose:
        plpy.execute("SET client_min_messages TO info")
    else:
        plpy.execute("SET client_min_messages TO error")

    start = time()
    col_len = len(col_names)
    col_names_as_float_array = py_list_to_sql_string(col_names, "float8")
    col_names_as_text_array = py_list_to_sql_string(col_names, "varchar")
    temp_table = unique_string()

    # actual computation
    plpy.execute("""
        CREATE TEMP TABLE {temp_table} AS
        SELECT
            tot_cnt,
            count(*) AS non_null_cnt,
            mean,
            {schema_madlib}.correlation_agg(x, mean) as cor_mat
        FROM
        (
            SELECT {col_names_as_float_array} AS x
            FROM {source_table}
        ) src1,
        (
            SELECT
                count(*) AS tot_cnt,
                {schema_madlib}.avg(x) AS mean
            FROM
            (
                SELECT {col_names_as_float_array} AS x
                FROM {source_table}
            ) src2
        ) subq
        WHERE NOT {schema_madlib}.array_contains_null(x)
        GROUP BY tot_cnt, mean
        """.format(**locals()))

    # create summary table
    summary_table = add_postfix(output_table, "_summary")
    q_summary = """
        CREATE TABLE {summary_table} AS
        SELECT
            'correlation'::varchar      AS method,
            '{source_table}'::varchar   AS source,
            '{output_table}'::varchar   AS output_table,
            '{cols}'::varchar  AS column_names,
            mean                        AS mean_vector,
            non_null_cnt                AS total_rows_processed,
            tot_cnt - non_null_cnt      AS total_rows_skipped
        FROM {temp_table}
        """.format(cols=', '.join(col_names), **locals())

    plpy.execute(q_summary)

    # create output table
    variable_list = []
    for k, c in enumerate(col_names):
        if k % 10 == 0:
            variable_list.append("\n                ")
        variable_list.append(str(c) + " float8")
        variable_list.append(",")
    variable_list_str = ''.join(variable_list[:-1])  # remove the last comma

    plpy.execute("""
        CREATE TABLE {output_table} AS
        SELECT
            *
        FROM
        (
            SELECT
                generate_series(1, {num_cols}) AS column_position,
                unnest({col_names_as_text_array}) AS variable
        ) variable_subq
        JOIN
        (
            SELECT
                *
            FROM
                {schema_madlib}.__deconstruct_lower_triangle(
                    (SELECT cor_mat FROM {temp_table})
                )
                AS deconstructed(column_position integer, {variable_list_str})
        ) matrix_subq
        USING (column_position)
        """.format(num_cols=len(col_names), **locals()))

    # clean up and return
    plpy.execute("DROP TABLE {temp_table}".format(**locals()))
    plpy.execute("SET client_min_messages TO " + old_msg_level)
    end = time()
    return (output_table, len(col_names), end - start)


# -----------------------------------------------------------------------
# Help messages
# -----------------------------------------------------------------------
def correlation_help_message(schema_madlib, message, **kwargs):
    """
    Given a help string, provide usage information
    """
    if message is not None and \
            message.lower() in ("usage", "help", "?"):
        return """
Usage:
-----------------------------------------------------------------------
SELECT {schema_madlib}.correlation
(
    source_table TEXT,   -- Source table name (Required)
    output_table TEXT,   -- Output table name (Required)
    target_cols  TEXT,   -- Comma separated columns for which summary is desired
                         --   (Default: '*' - produces result for all columns)
    verbose      BOOLEAN -- Verbosity
)
-----------------------------------------------------------------------
Output will be a table with N+2 columns and N rows, where N is the number
of numeric columns in 'target_cols'.
The columns of the table are described as follows:

    - column_position   : Position of the variable in the 'source_table'.
    - variable          : Provides the row-header for each variable
    - Rest of the table is the NxN correlation matrix for all numeric columns
    in 'source_table'.

The output table is arranged as a lower-traingular matrix with the upper
triangle set to NULL and the diagonal elements set to 1.0. To obtain the
result from the output_table in this matrix format ensure to order the
elements using the 'column_position' column.
        """.format(schema_madlib=schema_madlib)
    elif message is not None and message.lower() in ('example', 'examples'):
        return """
DROP TABLE IF EXISTS example_data;
CREATE TABLE example_data(
    id SERIAL,
    outlook text,
    temperature float8,
    humidity float8,
    windy text,
    class text) ;

INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('sunny', 85, 85, 'false', E'Dont Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('sunny', 80, 90, 'true', E'Dont Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('overcast', 83, 78, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('rain', 70, 96, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('rain', 68, 80, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('rain', 65, 70, 'true', E'Dont Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('overcast', 64, 65, 'true', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('sunny', 72, 95, 'false', E'Dont Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('sunny', 69, 70, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('rain', 75, 80, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('sunny', 75, 70, 'true', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('overcast', 72, 90, 'true', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('overcast', 81, 75, 'false', 'Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES('rain', 71, 80, 'true', E'Dont Play');
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES(NULL, 100, 100, 'true', NULL);
INSERT INTO example_data(outlook, temperature, humidity, windy, class)
VALUES(NULL, 110, 100, 'true', NULL);

SELECT madlib.correlation('example_data', 'example_data_output');
SELECT madlib.correlation('example_data', 'example_data_output', '*');
SELECT madlib.correlation('example_data', 'example_data_output', 'temperature, humidity');

To get the correlation matrix from output table:
SELECT * from example_data_output order by column_position;
         """
    else:
        return """
A correlation function is the degree and direction of association of
two variables; how well can one random variable be predicted
from the other. The coefficient of correlation varies from -1 to 1:
1 implies perfect correlation, 0 means no correlation, and -1 means
perfectly anti-correlated.
-------
For an overview on usage, run:
SELECT {schema_madlib}.correlation('usage');
-------
For an example, run:
SELECT {schema_madlib}.correlation('example')
            """.format(schema_madlib=schema_madlib)

